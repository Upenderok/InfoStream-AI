"""
Streamlit â€“ CPU-friendly RAG chat
---------------------------------
â€¢ Phi-3 mini via llama-cpp
â€¢ Retrieval = FAISS + BGE-small embeddings
â€¢ Strict â€œI donâ€™t knowâ€ fallback
"""

from __future__ import annotations
import sys
import pathlib
import streamlit as st

# â”€â”€â”€ make ./src importable no matter where Streamlit is launched â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ROOT = pathlib.Path(__file__).resolve().parent
sys.path.insert(0, str(ROOT / "src"))     # â†’ retriever.py, generator.py

from retriever import Retriever            # local module in src/
from generator import generate             # updated wrapper in src/

# â”€â”€â”€ page setup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="Document-Grounded Chat", layout="wide")
st.title("ðŸ“„ðŸ§  Document-Grounded Chat")

# chat history lives in session_state
if "chat" not in st.session_state:
    st.session_state.chat = []            # list[dict(role,text)]

# sidebar status & actions
retriever = Retriever()                   # loads FAISS & encoder
st.sidebar.success("Model & index loaded âœ”ï¸")
st.sidebar.write("**Model** : Phi-3-mini-q4")
st.sidebar.write(f"**Chunks indexed** : {retriever._index.ntotal}")
if st.sidebar.button("ðŸ—‘ï¸ Clear chat"):
    st.session_state.chat.clear()
    st.experimental_rerun()

# â”€â”€â”€ render previous turns â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
for turn in st.session_state.chat:
    st.chat_message(turn["role"]).markdown(
        turn["text"], unsafe_allow_html=False
    )

# â”€â”€â”€ user input â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
query = st.chat_input("Ask about the documentâ€¦")


def send_assistant(msg: str):
    st.chat_message("assistant").markdown(msg, unsafe_allow_html=False)
    st.session_state.chat.append({"role": "assistant", "text": msg})


if query:
    # record + echo user turn
    st.session_state.chat.append({"role": "user", "text": query})
    st.chat_message("user").markdown(query)

    with st.chat_message("assistant"):
        placeholder = st.empty()

        # â”€â”€ retrieve context â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        hits = retriever.search(query)
        if not hits:
            send_assistant(
                "I donâ€™t know â€” nothing in the document set matches that question."
            )
            st.stop()

        context = "\n\n".join(f"[{i}] {h['text']}" for i, h in enumerate(hits, 1))

        # â”€â”€ stream LLM â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        answer, buffer = "", []
        for tok in generate(context, query, stream=True):
            buffer.append(tok)
            # flush every ~30 tokens or on newline
            if len(buffer) >= 30 or "\n" in buffer[-1]:
                answer += "".join(buffer)
                placeholder.markdown(answer + " â–Œ", unsafe_allow_html=False)
                buffer = []

        answer += "".join(buffer)

        # â”€â”€ hide any residual prompt fragments just in case â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        answer = (
            answer.split("Instruction", 1)[0]
            .split("instruction", 1)[0]
            .strip()
        )

        placeholder.markdown(answer, unsafe_allow_html=False)  # final flush

        # â”€â”€ show sources â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        st.markdown("###### Sources used")
        for i, h in enumerate(hits, 1):
            excerpt = (
                (h["text"][:80] + "â€¦") if len(h["text"]) > 80 else h["text"]
            )
            st.markdown(f"- **[{i}]** p{h['page']} â€¢ *{excerpt}*")

        # log assistant turn
        st.session_state.chat.append({"role": "assistant", "text": answer})
